---
title: "Applied Project - Simulation and Empirical Study"
output: html_notebook
---

```{r }
# importing important packages
library(ggplot2)
library(dplyr)

# generating functions
sumfun <- function(x,start,end){
  return(sum(x[start:end]))
}

# the function calculates the power of a hypotheis test
pow <- function(x, cutoff){
  # x is the return series generated by alternative hypotheis
  H1_percentile <- ecdf(x)
  left_p <- H1_percentile(cutoff)[1]
  right_p <- H1_percentile(cutoff)[2]
  beta <- 1 - right_p + left_p
  return(beta)
}
```

```{r}


set.seed(123)
obs_list <-  vector('list', 100000)
ratios <- numeric(100000)
obs_overlap <-  vector(,264)
loss <-  numeric(100000)
loss_pr <- numeric(100000)
for (i in 1:100000){
  obs <- rnorm(n = 264, mean = 0, sd = 1)
  obs_long <- c(obs, rnorm(n = 9, mean = 0, sd= 1))
  for (j in 1:264){
    obs_overlap[j] <- sumfun(obs_long, j, j+9)
  }
  ratios[i] <- (quantile(obs_overlap,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs,probs = c(0.01), type = 4)))
  if (ratios[i] >1){
    loss[i] <-  abs((quantile(obs_overlap, probs = c(0.01), type = 4))- (sqrt(10) * quantile(obs, probs = c(0.01), type = 4)))
    loss_pr[i] <-  ratios[i] - 1
  }else{
    loss[i] = 0
    loss_pr[i] = 0
  }
}

sum(ratios >1) / length(ratios)
max(ratios)


df <- data.frame(ratios)
probs <- c(0.025, 0.5, 0.95, 0.975)
quantiles <- quantile(ratios, prob = probs, type = 1)
quantiles
```
```{r}
# plot
dens <- density(ratios)
dd <-  with(dens, data.frame(x,y))
conf_prob <- c(0.025, 0.975)
conf_quantiles <- quantile(ratios, prob = conf_prob, type = 1)
dd$quant <- factor(findInterval(dd$x, conf_quantiles))

ggplot(dd, aes(x, y)) + geom_line()+
    geom_ribbon(aes(ymin = 0, ymax = y, fill = quant)) +
  scale_x_continuous(breaks = quantiles, labels = round(quantiles, digits = 3)) +
  scale_fill_brewer(guide = "none")+
  xlab("Test Ratios") +ylab("Density") +
  annotate("text", x = 1.5, y = 0.8, label ="36.2% of 100000 paths has test ratio >= 1" , col = "red")+
  geom_vline(xintercept = 1, col = "red")+
  annotate('text',x = 1.1, y =0.2,label = "test ratio = 1")+
  ggtitle("Distribution of test ratios in N = 100000 pahts")

```



```{r}
### to test if the probability that Raio > 1 will converge for large number of simulations
MC <- seq(100, 10000, by = 100)
set.seed(123)
percent <-  numeric(length(MC))
for (num in (1:length(MC))){
  obs_list <- vector('list',MC[num] )
  obs_overlap <- vector(,273)
  ratios <- numeric(MC[num] )
  for (i in 1:MC[num] ){
  obs <- rnorm(n = 264, mean = 0, sd = 1)
  obs_long <- c(obs, rnorm(n = 9, mean = 0, sd= 1))
    for (j in 1:264){
    obs_overlap[j] <- sumfun(obs_long, j, j+9)
  }
  ratios[i] <- (quantile(obs_overlap,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs,probs = c(0.01), type = 4)))
  }
  percent[num] <- sum(ratios >1) / length(ratios)
}

percent_sim <- data.frame(MC, percent)
ggplot(percent_sim, aes(x = MC, y = percent)) + geom_point()
```

```{r}
########## H1: student-t distribution and power test  ############
cutoffs <- c(quantiles[1], quantiles[4])


S_t <- seq(2.5, 5, by = 0.5)
power_t <- vector(,length(S_t))
mean_t <- vector(,length(S_t))
avg_loss_t <- vector()
loss_t <-  vector()
loss_pr_t <- vector()
set.seed(123)
for (num in (1:length(S_t))){
  obs_list_t <- vector('list', 10000)
  obs_overlap_t <- vector(,273)
  ratios_t <- numeric(10000)
  for (i in 1:10000){
  obs_t <- rt(n = 264, df = S_t[num])
  obs_long_t <- c(obs_t,rt(n = 9, df = S_t[num]))
    for (j in 1:264){
    obs_overlap_t[j] <- sumfun(obs_long_t, j, j+9)
  }
  ratios_t[i] <- (quantile(obs_overlap_t,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs_t,probs = c(0.01), type = 4)))
  loss_t[i] <-  abs((quantile(obs_overlap_t, probs = c(0.01), type = 4))- (sqrt(10) * quantile(obs_t, probs = c(0.01), type = 4)))
  loss_pr_t[i] <- 1 - 1/ ratios_t[i] 
}
  power_t[num] <- pow(ratios_t, cutoffs)
  mean_t[num] <- mean(ratios_t)
  avg_loss_t[num] <- round(mean(loss_pr_t), digits = 6)
  print(quantile(ratios_t, prob = probs, type = 1))
}

power_t
avg_loss_t
mean_t
```

```{r}
######## H1: Non-zero Mean and power test #########
S_nm <- seq(-0.2, 0.2, by = 0.05)
power_nm <- vector(,length(S_nm))
avg_loss_nm <- vector()
mean_nm <- vector(,length(S_nm))
loss_nm <-  numeric(10000)
loss_pr_nm <- numeric(10000)
set.seed(123)
for (num in (1:length(S_nm))){
  obs_list_nm <- vector('list', 10000)
  obs_overlap_nm <- vector(,273)
  ratios_nm <- numeric(10000)
  for (i in 1:10000){
  obs_nm <- rnorm(n =264, mean = S_nm[num], sd = 1)
  obs_long_nm <- c(obs_nm,rnorm(n =9, mean = S_nm[num], sd = 1))
    for (j in 1:264){
    obs_overlap_nm[j] <- sumfun(obs_long_nm, j, j+9)
  }
  ratios_nm[i] <- (quantile(obs_overlap_nm,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs_nm,probs = c(0.01), type = 4)))
  loss_nm[i] <-  abs((quantile(obs_overlap_nm, probs = c(0.01), type = 4))- (sqrt(10) * quantile(obs_nm, probs = c(0.01), type = 4)))
  loss_pr_nm[i] <- 1 - 1/ ratios_nm[i] 
  }
  power_nm[num] <- pow(ratios_nm, cutoffs)
  mean_nm[num] <- mean(ratios_nm)
  avg_loss_nm[num] <- round(mean(loss_pr_nm), digits = 6)
  print(quantile(ratios_nm, prob = probs, type = 1))
}

power_nm
mean_nm
avg_loss_nm
```

```{r}
######## H1: AR(1) and power test #########

S_ar <- seq(-0.7, 0.7, by = 0.1)
power_ar <- vector(,length(S_ar))
mean_ar <- vector(,length(S_ar))
avg_loss_ar <- vector()
loss_ar <-  numeric(10000)
loss_pr_ar <- numeric(10000)
set.seed(123)
for (num in (1:length(S_ar))){
  obs_list_ar <- vector('list', 10000)
  obs_overlap_ar <- vector(,273)
  ratios_ar <- numeric(10000)
  for (i in 1:10000){
  obs_ar <- as.numeric(arima.sim(n=264,list(ar = S_ar[num], ma=0, sd= sqrt(0.15))))
  obs_long_ar <- c(obs_ar,as.numeric(arima.sim(n=9,list(ar = S_ar[num], ma=0, sd= sqrt(0.15)))))
    for (j in 1:264){
    obs_overlap_ar[j] <- sumfun(obs_long_ar, j, j+9)
  }
  ratios_ar[i] <- (quantile(obs_overlap_ar,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs_ar,probs = c(0.01), type = 4)))
  loss_ar[i] <-  abs((quantile(obs_overlap_ar, probs = c(0.01), type = 4))- (sqrt(10) * quantile(obs_ar, probs = c(0.01), type = 4)))
  loss_pr_ar[i] <- 1 - 1/ ratios_ar[i] 
  }
  power_ar[num] <- pow(ratios_ar, cutoffs)
  avg_loss_ar[num] <- round(mean(loss_pr_ar), digits = 6)
  mean_ar[num] <- mean(ratios_ar)
  print(quantile(ratios_ar, prob = probs, type = 1))
}

power_ar
avg_loss_ar
mean_ar


```

```{r}
######## H1: GARCH(1,1) and power test #########
library(fGarch)
alphas <- c(0.130, 0.150, 0.130, 0.150)
betas  <- c(0.820, 0.800, 0.840, 0.820)


power_garch <- vector(,length(alphas))
avg_loss_garch <- vector()
mean_garch <- vector(,length(alphas))
loss_garch <-  numeric(10000)
loss_pr_garch <- numeric(10000)
set.seed(123)


for (num in (1:length(alphas))){
  obs_list_garch <- vector('list', 10000)
  obs_overlap_garch <- vector(,273)
  ratios_garch <- numeric(10000)
  for (i in 1:10000){
    
  spec =garchSpec(model = list(omega = 1e-4, alpha = alphas[num], beta = betas[num]))
  obs_garch <- as.numeric(garchSim(spec, n = 264))
  obs_long_garch <- c(obs_garch,as.numeric(garchSim(spec, n = 9)))
    for (j in 1:264){
    obs_overlap_garch[j] <- sumfun(obs_long_garch, j, j+9)
  }
  ratios_garch[i] <- (quantile(obs_overlap_garch,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs_garch,probs = c(0.01), type = 4)))
  

  loss_garch[i] <-  abs((quantile(obs_overlap_garch, probs = c(0.01), type = 4))- (sqrt(10) * quantile(obs_garch, probs = c(0.01), type = 4)))
  loss_pr_garch[i] <-  1 - 1/ ratios_garch[i] 

  }
  power_garch[num] <- pow(ratios_garch, cutoffs)
  mean_garch[num] <- mean(ratios_garch)
  avg_loss_garch[num] <- round(mean(loss_pr_garch), digits = 6)
  print(quantile(ratios_garch, prob = probs, type = 1))
}

power_garch
avg_loss_garch
mean_garch

```


```{r}
## To get the characteristics of real asset returns
## Data Processing
file_list <- list.files(pattern = "*.csv")
list_of_dataframes <- lapply(file_list, read.csv)

# Process each dataframe
for (i in 1:length(list_of_dataframes)) {
  
  # Select first and last columns
  df <- list_of_dataframes[[i]][1:273, c(1, ncol(list_of_dataframes[[i]]))]
  
  # Rename the last column to "Return"
  colnames(df)[ncol(df)] <- "Returns"
  
  df$Date <- as.Date(df$Date, format="%d/%m/%Y")
  df$Returns <- as.numeric(as.character(df$Returns))
  
  # Update the dataframe in the list
  list_of_dataframes[[i]] <- df
  
  base_name <- tools::file_path_sans_ext(file_list[i])
  
  # Assign dataframe to global environment with file base name
  assign(base_name, df)
  
  # Print the column names for each dataframe
  cat(sprintf("For dataframe df_%d, the columns are: %s and %s\n", i, 
              names(df)[1], 
              names(df)[2]))
}

# If you still want to assign them to individual dataframes in your global environment
for (i in 1:length(file_list)) {
  assign(paste0("df", i), list_of_dataframes[[i]])
}

## now we should have clean dataframes
tail(Gol, 5)
```


```{r}
####  Data Fitting for  SP500 2008####
library(sandwich)
library(dynlm)
library(lmtest)
library(fGarch)
library(rugarch)
#get the mean
print(mean(SP500_2008$Returns[1:264]))
t.test(SP500_2008$Returns[1:264])

#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = SP500_2008)
print(coeftest(ar1,vcov. = sandwich))

#Get the log-log rank size tail index
# Use previous AFS solution

#Get GARCH coefficients
garchFit(~ garch(1,1), data = SP500_2008$Returns, trace = FALSE)
```
```{r}
####  Data Fitting for  SP500 20023####
#get the mean
print(mean(SP500_2023$Returns[1:264]))
t.test(SP500_2023$Returns[1:264])

#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = SP500_2023)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = SP500_2023$Returns, trace = FALSE)

```
```{r}
####  Data Fitting for Gold Future 2008####
#get the mean
print(mean(Gold_2008$Returns[1:264]))
t.test(Gold_2008$Returns[1:264])

#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = Gold_2008)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = Gold_2008$Returns, trace = FALSE)


```
```{r}
####  Data Fitting for Gold Future 2023####
#get the mean
print(mean(Gold_2023$Returns[1:264]))
t.test(Gold_2023$Returns[1:264])

#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = Gold_2023)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = Gold_2023$Returns, trace = FALSE)
```
```{r}
####  Data Fitting for  BMW 2008####
print(mean(BMW_2008$Returns[1:264]))
t.test(BMW_2008$Returns[1:264])
#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = BMW_2008)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = BMW_2008$Returns, trace = FALSE)
```
```{r}
####  Data Fitting for  BMW 2023####
print(mean(BMW_2023$Returns[1:264]))
t.test(BMW_2023$Returns[1:264])
#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = BMW_2023)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = BMW_2023$Returns, trace = FALSE)
```

```{r}
####  Data Fitting for  EXR 2008####
print(mean(USD_GBP_2008$Returns[1:264]))
t.test(USD_GBP_2008$Returns[1:264])
#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data = USD_GBP_2008)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = USD_GBP_2008$Returns, trace = FALSE)
```

```{r}
####  Data Fitting for  EXR 2023####
print(mean(USD_GBP_2023$Returns[1:264]))
t.test(USD_GBP_2023$Returns[1:264])
#get the AR coefficients
ar1 <- dynlm(ts(Returns) ~L(ts(Returns)), data =USD_GBP_2023)
print(coeftest(ar1,vcov. = sandwich))

#Get GARCH coefficients
garchFit(~ garch(1,1), data = USD_GBP_2023$Returns, trace = FALSE)
```

```{r}
### Adding GARCH Simulation

library(fGarch)


avg_loss_garch_new <- vector()
loss_garch_new <-  numeric(10000)
loss_pr_garch_new <- numeric(10000)
set.seed(123)



obs_list_garch_new <- vector('list', 10000)
obs_overlap_garch_new <- vector(,273)
ratios_garch_new <- numeric(10000)
for (i in 1:10000){
  spec_new =garchSpec(model = list(omega = 1e-6, alpha = 0.08, beta = 0.89))
  obs_garch_new <- as.numeric(garchSim(spec_new, n = 264))
  obs_long_garch_new <- c(obs_garch_new,as.numeric(garchSim(spec_new, n = 9)))
    for (j in 1:264){
    obs_overlap_garch_new[j] <- sumfun(obs_long_garch_new, j, j+9)
  }
  ratios_garch_new[i] <- (quantile(obs_overlap_garch_new,probs = c(0.01), type = 4)/ (sqrt(10) * quantile(obs_garch_new,probs = c(0.01), type = 4)))
  

  loss_garch_new[i] <-  abs((quantile(obs_overlap_garch_new, probs = c(0.01), type = 4))- (sqrt(10) * quantile(obs_garch_new, probs = c(0.01), type = 4)))
  loss_pr_garch_new[i] <-  1 - 1/ ratios_garch_new[i] 
  }
mean(loss_pr_garch_new)
mean(ratios_garch_new)
print(quantile(ratios_garch_new, prob = probs, type = 1))
pow(ratios_garch_new, cutoffs)

```


```{r}
library(fGarch)
library(xts)


xts_data <- xts(Gold_2023$Returns, order.by = as.Date(Gold_2023$Date))

plot(xts_data, col = "blue", main = "Gold Futures Returns")




```


